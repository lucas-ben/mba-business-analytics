{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47b7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score,\n",
    "                             precision_score, recall_score, confusion_matrix,\n",
    "                             log_loss, RocCurveDisplay, PrecisionRecallDisplay, average_precision_score, precision_recall_curve, auc,\n",
    "                             DetCurveDisplay, ConfusionMatrixDisplay, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b10b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data sets\n",
    "df_train = pd.read_csv('train.csv', delimiter = ';')\n",
    "df_test = pd.read_csv('test.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e927852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f3f77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9efa4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Test Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set NaNs\\n{df_train.isnull().sum()}\")\n",
    "print(f\"Test Set NaNs\\n{df_test.isnull().sum()}\") # checking for NaN and nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a75135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 288\n",
      "marital: 0\n",
      "education: 1857\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 13020\n",
      "month: 0\n",
      "poutcome: 36959\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in training set\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        unknown_count = (df_train[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a51dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 38\n",
      "marital: 0\n",
      "education: 187\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 1324\n",
      "month: 0\n",
      "poutcome: 3705\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in test set\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        unknown_count = (df_test[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d229d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring class distribution of dependent variable\n",
    "dic = {'no': 0, 'yes': 1} # creating binary dictionary for response variable\n",
    "\n",
    "df_train['y'] = df_train['y'].map(dic)\n",
    "df_test['y'] = df_test['y'].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e398f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of training set response variable classes 0.11698480458295547\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of training set response variable classes {df_train['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d1218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test set response variable classes 0.11523999115239991\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of test set response variable classes {df_test['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ba86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y                 0     1\n",
      "job                      \n",
      "admin.         4540   631\n",
      "blue-collar    9024   708\n",
      "entrepreneur   1364   123\n",
      "housemaid      1131   109\n",
      "management     8157  1301\n",
      "retired        1748   516\n",
      "self-employed  1392   187\n",
      "services       3785   369\n",
      "student         669   269\n",
      "technician     6757   840\n",
      "unemployed     1101   202\n",
      "unknown         254    34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contingency_table = pd.crosstab(df_train['job'], df_train['y']) # creating contingency table\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea48054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared statistic 836.1054877471965\n",
      "p-value 3.337121944935502e-172\n",
      "df 11\n"
     ]
    }
   ],
   "source": [
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"chi-squared statistic {chi2}\")\n",
    "print(f\"p-value {p_value}\")\n",
    "print(f\"df {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24541bc6",
   "metadata": {},
   "source": [
    "- Careers with above average conversion rates:\n",
    "    - Students **28.7%**\n",
    "    - Retired **22.8%**\n",
    "\n",
    "- Careers with below average conversion rates:\n",
    "    - Blue-collar **7.3%**\n",
    "    - Entrepreneur **8.3%**\n",
    "\n",
    "- p-value < 0.05 so reject the null that career type doesn't influence responding well to campaign\n",
    "\n",
    "**Career type and responding positively to the campaign are dependent**\n",
    "\n",
    "The chi-squared test (χ² = 836.11, p < 0.001) provides overwhelming evidence that job type and subscription decisions are strongly related. This suggests that profession is a critical factor in customer behavior and should be prioritized in both feature selection and business strategy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948f1f2",
   "metadata": {},
   "source": [
    "**Feature Engineering Ideas**\n",
    "- Categorize variables\n",
    "    - Categorize 'month' (last contact month of the year) into Q1-Q4\n",
    "        - Q1-Q4\n",
    "    - Categorize 'job' into currently working or currently not working\n",
    "        - Currently not working: students, retirees\n",
    "        - Categories of jobs (white collar salaried jobs, blue-collared salaried jobs, variable income (entrepreneurs))\n",
    "        - With these buckets I won't have to use 'education' which is probably collinear with 'job'\n",
    "    - Categorize 'balance' into different buckets of wealth\n",
    "    - Categorize 'day' (last contact day of the month) into buckets\n",
    "        - Could learn the average time of the month people usually pay their bills or repay their debt for most banks\n",
    "    - Categorize 'duration' into buckets of types of clients\n",
    "    - Categorize 'campaign' (number of contacts performed during this campaign and for this client)\n",
    "        - Could be buckets of frequently contacted (see if they subscribed in the past if clients were contacted more or if it bothered them into not subscribing)\n",
    "        - Same for 'previous'\n",
    "    - Categorize 'pdays' (number of days that passed by after the client was last contacted from a previous campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc01ef",
   "metadata": {},
   "source": [
    "1. Train baseline model with original features\n",
    "2. Add engineered features incrementally\n",
    "3. Compare model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3c1f0",
   "metadata": {},
   "source": [
    "## **Baseline Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline logistic regression model\n",
    "X_train = df_train.drop('y', axis=1)\n",
    "y_train = df_train['y']\n",
    "\n",
    "X_test = df_test.drop('y', axis=1)\n",
    "y_test = df_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b32d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "num_feats = ['age', 'balance', 'campaign', 'pdays', 'previous', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76abd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_feats)\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "pred_proba = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d4ceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.5920\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, pred)\n",
    "print(f\"\\nPrecision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b29eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall: 0.1420\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, pred)  \n",
    "print(f\"\\nRecall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0703af2",
   "metadata": {},
   "source": [
    "## **Baseline K-NN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_feats)\n",
    "    ])\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fca16e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== k-NN Model Performance ===\n",
      "Precision: 0.7110\n",
      "Recall: 0.2975\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision_knn = precision_score(y_test, pred_knn, pos_label=1)\n",
    "recall_knn = recall_score(y_test, pred_knn, pos_label=1)\n",
    "\n",
    "print(\"=== k-NN Model Performance ===\")\n",
    "print(f\"Precision: {precision_knn:.4f}\")\n",
    "print(f\"Recall: {recall_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4e710c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ap_lr \u001b[38;5;241m=\u001b[39m average_precision_score(y_test, lr\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m ap_knn \u001b[38;5;241m=\u001b[39m average_precision_score(y_test, knn\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      5\u001b[0m PrecisionRecallDisplay\u001b[38;5;241m.\u001b[39mfrom_estimator(\n\u001b[1;32m      6\u001b[0m     lr, X_test, y_test,\n\u001b[1;32m      7\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression (AP=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00map_lr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     ax\u001b[38;5;241m=\u001b[39max\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn' is not defined"
     ]
    }
   ],
   "source": [
    "ap_lr = average_precision_score(y_test, lr.predict_proba(X_test)[:, 1])\n",
    "ap_knn = average_precision_score(y_test, knn.predict_proba(X_test)[:, 1])\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(\n",
    "    lr, X_test, y_test,\n",
    "    name=f'Logistic Regression (AP={ap_lr:.2f})',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(\n",
    "    knn, X_test, y_test, \n",
    "    name=f'KNN (AP={ap_knn:.2f})',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Use different colors and add edge colors for visibility\n",
    "ax.scatter(recall, precision, color='darkblue', s=150, marker='o', \n",
    "           edgecolors='black', linewidths=2,\n",
    "           label=f'LR Current (P={precision:.2f}, R={recall:.2f})', zorder=5)\n",
    "ax.scatter(recall_knn, precision_knn, color='darkorange', s=150, marker='o', \n",
    "           edgecolors='black', linewidths=2,\n",
    "           label=f'KNN Current (P={precision_knn:.2f}, R={recall_knn:.2f})', zorder=5)\n",
    "\n",
    "plt.title('Precision-Recall Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda80af7",
   "metadata": {},
   "source": [
    "**Baseline Model Evaluation**\n",
    "- Logistic regression had higher precision than recall (over 4x) and k-NN had higher precision than recall (more than 2x). By using these models, running another telemarketing campaign can capture a segment of our clients who will leave term deposits somewhat efficiently, however we would miss a chunk of clients who would have also subscribed to more term deposits.\n",
    "\n",
    "- Advantages of higher precision than recall are if we have budget constraints for our telemarketing campaign and want to reduce the risk of losing customers do to false positive cases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13043c02",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f6701c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating binary feature for job type with highest historical success rate\n",
    "X_train['high_value_job'] = X_train['job'].isin(['student', 'retired']).astype(int)\n",
    "# creating binary feature for previous success with client\n",
    "X_train['previous_success'] = (X_train['poutcome'] == 'success').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a80c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['high_value_job'] = X_test['job'].isin(['student', 'retired']).astype(int)\n",
    "X_test['previous_success'] = (X_test['poutcome'] == 'success').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8ab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['marital', 'education', 'default', 'housing', 'loan', 'contact', 'month']\n",
    "num_feats = ['age', 'balance', 'campaign', 'pdays', 'previous', 'day', 'high_value_job', 'previous_success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0437cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_feats)\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr_2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "lr_2.fit(X_train, y_train)\n",
    "\n",
    "pred_2 = lr_2.predict(X_test)\n",
    "pred_proba_2 = lr_2.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "967522da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.5906\n",
      "\n",
      "Recall: 0.1440\n"
     ]
    }
   ],
   "source": [
    "precision_2 = precision_score(y_test, pred_2)\n",
    "print(f\"\\nPrecision: {precision_2:.4f}\")\n",
    "\n",
    "recall_2 = recall_score(y_test, pred_2)  \n",
    "print(f\"\\nRecall: {recall_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096ec68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_feats)\n",
    "    ])\n",
    "\n",
    "knn_2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_2.fit(X_train, y_train)\n",
    "\n",
    "pred_knn_2 = knn_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6202926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== k-NN Model Performance ===\n",
      "Precision: 0.7149\n",
      "Recall: 0.3321\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision_knn_2 = precision_score(y_test, pred_knn_2, pos_label=1)\n",
    "recall_knn_2 = recall_score(y_test, pred_knn_2, pos_label=1)\n",
    "\n",
    "print(\"=== k-NN Model Performance ===\")\n",
    "print(f\"Precision: {precision_knn_2:.4f}\")\n",
    "print(f\"Recall: {recall_knn_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da1a0e",
   "metadata": {},
   "source": [
    "## **Balancing Class Distribution Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b278be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5db750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after resampling: 79844\n",
      "Precision: 0.2450\n",
      "Recall:    0.5681\n"
     ]
    }
   ],
   "source": [
    "lr_resampled = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "lr_resampled.fit(X_train, y_train)\n",
    "pred_lr = lr_resampled.predict(X_test)\n",
    "pred_proba_lr = lr_resampled.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision_lr = precision_score(y_test, pred_lr)\n",
    "recall_lr = recall_score(y_test, pred_lr)\n",
    "\n",
    "\n",
    "print(f\"Training samples after resampling: {lr_resampled.named_steps['oversampler'].sample_indices_.shape[0]}\")\n",
    "print(f\"Precision: {precision_lr:.4f}\")\n",
    "print(f\"Recall:    {recall_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c628fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after resampling: 79844\n",
      "Precision: 0.4605\n",
      "Recall:    0.9962\n"
     ]
    }
   ],
   "source": [
    "# Use ImbPipeline instead of Pipeline\n",
    "knn_resampled = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_resampled.fit(X_train, y_train)\n",
    "\n",
    "pred_knn = knn_resampled.predict(X_test)\n",
    "pred_proba_knn = knn_resampled.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision_knn = precision_score(y_test, pred_knn)\n",
    "recall_knn = recall_score(y_test, pred_knn)\n",
    "\n",
    "print(f\"Training samples after resampling: {knn_resampled.named_steps['oversampler'].sample_indices_.shape[0]}\")\n",
    "print(f\"Precision: {precision_knn:.4f}\")\n",
    "print(f\"Recall:    {recall_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f657ce",
   "metadata": {},
   "source": [
    "**logistic regression cv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdff8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (inverse regularization strength): [0.00599484]\n",
      "Best scores per fold: [0.         0.00583746 0.1516074  0.09044516 0.07067816 0.07003791\n",
      " 0.07003791 0.06996173 0.06983881 0.06986681]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_feats)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build pipeline with LogisticRegressionCV\n",
    "lr_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegressionCV(\n",
    "        cv=5,                          # 5-fold cross-validation\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        scoring='f1',                  # Can use 'accuracy', 'roc_auc', 'f1', etc.\n",
    "        n_jobs=-1                      # Use all available cores for faster training\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "lr_cv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred_cv = lr_cv.predict(X_test)\n",
    "pred_proba_cv = lr_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Check the best regularization parameter found\n",
    "print(f\"Best C (inverse regularization strength): {lr_cv.named_steps['classifier'].C_}\")\n",
    "print(f\"Best scores per fold: {lr_cv.named_steps['classifier'].scores_[1].mean(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0e7f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.7500\n",
      "Recall:    0.0921\n"
     ]
    }
   ],
   "source": [
    "precision_cv = precision_score(y_test, pred_cv)\n",
    "recall_cv = recall_score(y_test, pred_cv)\n",
    "print(f\"\\nPrecision: {precision_cv:.4f}\")\n",
    "print(f\"Recall:    {recall_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "088290bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With RandomOverSampler:\n",
      "Best C: [0.0001]\n",
      "Best F1 scores: [0.61323637 0.58983643 0.54979188 0.53368788 0.53060944 0.53005168\n",
      " 0.52992831 0.52990986 0.52990986 0.52990986]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "lr_cv_resampled = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', LogisticRegressionCV(\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "lr_cv_resampled.fit(X_train, y_train)\n",
    "pred_cv_resampled = lr_cv_resampled.predict(X_test)\n",
    "\n",
    "print(f\"\\nWith RandomOverSampler:\")\n",
    "print(f\"Best C: {lr_cv_resampled.named_steps['classifier'].C_}\")\n",
    "print(f\"Best F1 scores: {lr_cv_resampled.named_steps['classifier'].scores_[1].mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c457ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.2052\n",
      "Recall:    0.6238\n"
     ]
    }
   ],
   "source": [
    "precision_cv_resampled = precision_score(y_test, pred_cv_resampled)\n",
    "recall_cv_resampled = recall_score(y_test, pred_cv_resampled)\n",
    "print(f\"\\nPrecision: {precision_cv_resampled:.4f}\")\n",
    "print(f\"Recall:    {recall_cv_resampled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b1f4bc",
   "metadata": {},
   "source": [
    "## **Ensembel Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d62ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
