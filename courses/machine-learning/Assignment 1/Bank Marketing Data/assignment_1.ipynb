{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47b7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score,\n",
    "                             precision_score, recall_score, confusion_matrix,\n",
    "                             log_loss, RocCurveDisplay, PrecisionRecallDisplay,\n",
    "                             DetCurveDisplay, ConfusionMatrixDisplay, brier_score_loss, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b10b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data sets\n",
    "df_train = pd.read_csv('train.csv', delimiter = ';')\n",
    "df_test = pd.read_csv('test.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e927852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9efa4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Test Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set NaNs\\n{df_train.isnull().sum()}\")\n",
    "print(f\"Test Set NaNs\\n{df_test.isnull().sum()}\") # checking for NaN and nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a75135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 288\n",
      "marital: 0\n",
      "education: 1857\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 13020\n",
      "month: 0\n",
      "poutcome: 36959\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in training set\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        unknown_count = (df_train[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a51dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 38\n",
      "marital: 0\n",
      "education: 187\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 1324\n",
      "month: 0\n",
      "poutcome: 3705\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in test set\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        unknown_count = (df_test[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d229d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring class distribution of dependent variable\n",
    "dic = {'no': 0, 'yes': 1} # creating binary dictionary for response variable\n",
    "\n",
    "df_train['y'] = df_train['y'].map(dic)\n",
    "df_test['y'] = df_test['y'].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e398f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of training set response variable classes 0.11698480458295547\n"
     ]
    }
   ],
   "source": [
    "training_conversion_rate = df_train['y'].mean()\n",
    "print(f\"Mean of training set response variable classes {df_train['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d1218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test set response variable classes 0.11523999115239991\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of test set response variable classes {df_test['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2ba86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y                 0     1\n",
      "job                      \n",
      "admin.         4540   631\n",
      "blue-collar    9024   708\n",
      "entrepreneur   1364   123\n",
      "housemaid      1131   109\n",
      "management     8157  1301\n",
      "retired        1748   516\n",
      "self-employed  1392   187\n",
      "services       3785   369\n",
      "student         669   269\n",
      "technician     6757   840\n",
      "unemployed     1101   202\n",
      "unknown         254    34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contingency_table = pd.crosstab(df_train['job'], df_train['y']) # creating contingency table\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea48054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared statistic 836.1054877471965\n",
      "p-value 3.337121944935502e-172\n",
      "df 11\n"
     ]
    }
   ],
   "source": [
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"chi-squared statistic {chi2}\")\n",
    "print(f\"p-value {p_value}\")\n",
    "print(f\"df {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24541bc6",
   "metadata": {},
   "source": [
    "- Careers with above average conversion rates:\n",
    "    - Students **28.7%**\n",
    "    - Retired **22.8%**\n",
    "\n",
    "- Careers with below average conversion rates:\n",
    "    - Blue-collar **7.3%**\n",
    "    - Entrepreneur **8.3%**\n",
    "\n",
    "- p-value < 0.05 so reject the null that career type doesn't influence responding well to campaign\n",
    "\n",
    "**Career type and responding positively to the campaign are dependent**\n",
    "\n",
    "The chi-squared test (χ² = 836.11, p < 0.001) provides overwhelming evidence that job type and subscription decisions are strongly related. This suggests that profession is a critical factor in customer behavior and should be prioritized in both feature selection and business strategy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948f1f2",
   "metadata": {},
   "source": [
    "**Feature Engineering Ideas**\n",
    "- Categorize variables\n",
    "    - Categorize 'month' (last contact month of the year) into seasons\n",
    "        - Q1-Q4\n",
    "        - Seasons\n",
    "    - Categorize 'job' into currently working or currently not working\n",
    "        - Currently not working: students, retirees\n",
    "        - Categories of jobs (white collar salaried jobs, blue-collared salaried jobs, variable income (entrepreneurs))\n",
    "        - With these buckets I won't have to use 'education' which is probably collinear with 'job'\n",
    "    - Categorize 'balance' into different buckets of wealth\n",
    "    - Categorize 'day' (last contact day of the month) into buckets\n",
    "        - Could learn the average time of the month people usually pay their bills or repay their debt for most banks\n",
    "    - Categorize 'duration' into buckets of types of clients\n",
    "    - Categorize 'campaign' (number of contacts performed during this campaign and for this client)\n",
    "        - Could be buckets of frequently contacted (see if they subscribed in the past if clients were contacted more or if it bothered them into not subscribing)\n",
    "        - Same for 'previous'\n",
    "    - Categorize 'pdays' (number of days that passed by after the client was last contacted from a previous campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cf9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
