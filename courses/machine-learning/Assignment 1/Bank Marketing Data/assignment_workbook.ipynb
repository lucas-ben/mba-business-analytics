{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a941c9c",
   "metadata": {},
   "source": [
    "# **Ensemble Learning in Action**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f432e",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "Build, evaluate, and compare ensemble models while demonstrating an understanding of model mechanics, trade-offs, and business implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score,\n",
    "                             precision_score, recall_score, confusion_matrix,\n",
    "                             log_loss, RocCurveDisplay, PrecisionRecallDisplay,\n",
    "                             DetCurveDisplay, ConfusionMatrixDisplay, brier_score_loss)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b183877",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "**Model Selection & Validation**\n",
    "- cross_val_score: Performs cross-validation to evaluate model performance\n",
    "- StratifiedKFold: Performs cross-validation that maintains class distributions\n",
    "\n",
    "**Data Preprocessing**\n",
    "- ColumnTransformer: Applies different preprocessing to different columns\n",
    "- OneHotEncoderL Applies one hot encoding\n",
    "- StandardScaler: Normalizes features to the same scale\n",
    "- SimpleImputer: Imputes missing values\n",
    "- Pipeline: Chains preprocessing and modelling steps together\n",
    "\n",
    "**Model Analysis**\n",
    "- permutation_importance: Determines feature importance by shuffling features\n",
    "\n",
    "**Evaluation Metrics**\n",
    "- accuracy_score\n",
    "- f1_score\n",
    "- precision_score\n",
    "- recall_score\n",
    "- roc_auc_score\n",
    "- confusion_matrix\n",
    "- log_loss\n",
    "- brier_score_loss\n",
    "\n",
    "**Classification Algorithms**\n",
    "- LogisticRegression\n",
    "- KNeighborsClassifier\n",
    "- BaggingClassifier\n",
    "- AdaBoostClassifier\n",
    "- RandomForestClassifier\n",
    "- VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19489850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data sets\n",
    "df_train = pd.read_csv('train.csv', delimiter = ';')\n",
    "df_test = pd.read_csv('test.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7e27f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1883c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Test Set NaNs\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set NaNs\\n{df_train.isnull().sum()}\")\n",
    "print(f\"Test Set NaNs\\n{df_test.isnull().sum()}\") # checking for NaN and nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d74239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 288\n",
      "marital: 0\n",
      "education: 1857\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 13020\n",
      "month: 0\n",
      "poutcome: 36959\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in training set\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        unknown_count = (df_train[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50a8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: 38\n",
      "marital: 0\n",
      "education: 187\n",
      "default: 0\n",
      "housing: 0\n",
      "loan: 0\n",
      "contact: 1324\n",
      "month: 0\n",
      "poutcome: 3705\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for 'unknown' values in categorical columns in test set\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        unknown_count = (df_test[col] == 'unknown').sum()\n",
    "        print(f\"{col}: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838643b",
   "metadata": {},
   "source": [
    "When I first started exploring the class distribution of the output variable, I realized it was an object with a binary response for the observations,'yes' and 'no', which described whether a client subscribed to a term deposit. To make my analysis easier, I defined a dictionary where 'no' equals 0 and 'yes' equals 1 then mapped it to both the training and test sets. Following this, I transformed the output variable from an object to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80848555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring class distribution of dependent variable\n",
    "dic = {'no': 0, 'yes': 1} # creating binary dictionary for response variable\n",
    "\n",
    "df_train['y'] = df_train['y'].map(dic)\n",
    "df_test['y'] = df_test['y'].map(dic)\n",
    "\n",
    "df_train['y'] = df_train['y'].astype(int) \n",
    "df_test['y'] = df_test['y'].astype(int) # changing the output variable from an object to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6e1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of training set response variable classes 0.11698480458295547\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of training set response variable classes {df_train['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b270685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test set response variable classes 0.11523999115239991\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of test set response variable classes {df_test['y'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29611a",
   "metadata": {},
   "source": [
    "Both the mean of the training and test set response variable show the majority class is no. This means most clients do not subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ca0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining majority and minority classes for both data sets for exploration\n",
    "train_majority = df_train[df_train['y'] == 0]\n",
    "test_majority = df_test[df_test['y'] == 0]\n",
    "\n",
    "train_minority = df_train[df_train['y'] == 1]\n",
    "test_minority = df_test[df_test['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94dcec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set majority class dimensions (39922, 17)\n",
      "Training set minority class dimensions (5289, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set majority class dimensions {train_majority.shape}\")\n",
    "print(f\"Training set minority class dimensions {train_minority.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6ce659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minority class of the training set makes up 13.25% of the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"The minority class of the training set makes up {5289/39922 * 100:.2f}% of the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701a8014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set majority class dimensions (4000, 17)\n",
      "Test set minority class dimensions (521, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set majority class dimensions {test_majority.shape}\")\n",
    "print(f\"Test set minority class dimensions {test_minority.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789b82d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minority class of the test set makes up 13.03% of the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"The minority class of the test set makes up {521/4000 *100:.2f}% of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390dd22",
   "metadata": {},
   "source": [
    "There is a large class imbalance between clients who do subscribe to a term deposit and those who don't. This is a severely class-imbalanced data set.\n",
    "\n",
    "Data imbalance refers to the concept where a certain output category is underrepresented in a data set. Class-imbalanced data sets are far more common than class-balanced data sets. The goal of training is to create a model that successfully distinguishes the positive class from the negative class. A severely class-imbalanced data set might not contain enough minority class examples for proper training. During training a model should learn what each class looks like (what feature calues correspond to what class) and how common each class is (what is the relative distribution of the classes). These questions can be addressed with a two-step technique downsampling and upweighting the majority class.\n",
    "\n",
    "**1.** Downsampling the majority class means training on a disproportionately low percentage of majority class observations. I artificially force a class-imbalanced data set to become a little more balanced by omitting majority class examples from training. This increases the likelihood that each batch contains enough obsevations of the minority class to train the model properly. However, downsampling introduces a prediction bias by showing the model an unrealistic reality where the classes are more balanced.\n",
    "\n",
    "**2.** Upweighting the majority class is where the majority class is weighted by the factor to which it was downsampled. Upweigthing means treating the loss on a majority class observation more harshly than the loss on a minority class observation. This will multiply the loss on one observation by the factor to which the majority class was downsampled. \n",
    "\n",
    "Experiment with hyperparameters to determine the factor to use to rebalance the data set. A bonus of this method is faster convergence as the model sees the minority class more often during training. \n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/overfitting/imbalanced-datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86932d96",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis** \n",
    "- Analyze the data set to summarize its main characteristics (use visuals, statistical models)\n",
    "- I want to see what the data can tell me beyond the formal modelling or hypothesis testing task\n",
    "\n",
    "**Ask myself** What patterns, anomalies, or relationships exist here that I might not anticipate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663b42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
